---
title: "Proof of Concept"
bibliography: references.bib
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 2
    self-contained: true
---


```{r suppress_startup_msg, include = FALSE}
# Invisible code chunk to suppress package startup messages later on
suppressPackageStartupMessages(library("tidyverse"))
suppressPackageStartupMessages(library("bamlss"))
suppressPackageStartupMessages(library("digest"))
suppressPackageStartupMessages(library("lemon"))
# Disable readr from showing output when calling read_csv
options(readr.show_progress = FALSE)
options(readr.show_col_types = FALSE)
```


This section prooves the suitability of the (hacky phase) post-processing
benchmark data set for testing post-processing techniques for near surface temperature.
While many different post-processing methods have been proposed in
the literature over the past decades, this section makes use of one of the
models proposed by @lang2020, a station-based non-homogeneous Gaussian model
with smoothly varying seasonal effects. For demonstration, the method is
applied to three stations across Germany for two different forecast horizons.



#### Data

The three stations are chosen (@tbl-stations) to cover different
climatic zones with Emden close to the coast of the North Sea, Wasserkuppe in
moderately complex topography in the center of the country, and Oberstdorf
located in a complex topographic environment in the Allg√§u Alps at the southern
boarder of Germany.

```{r stations, echo = FALSE}
#| label: tbl-stations
#| tbl-cap: Stations used in the case study. Altitude in meters a.m.s.l.,
#|          longitude and latitude in degrees East and North, respectively.
tmp <- read_csv("eupp_station_meta.csv")
knitr::kable(transmute(tmp,
                       Name      = station_name,
                       Altitude  = as.integer(round(altitude)),
                       Longitude = round(longitude, 4),
                       Latitude  = round(latitude,  4)))
```

```{r}
#| echo: false
#| fig: true
suppressPackageStartupMessages(library("sf"))
suppressPackageStartupMessages(library("rnaturalearth"))

DEU <- ne_countries(scale = "medium", returnclass = "sf")
DEU <- st_geometry(subset(DEU, adm0_a3_is == "DEU"))
meta <- st_as_sf(read_csv("eupp_station_meta.csv"),
                 coords = c("longitude", "latitude"), crs = st_crs(DEU))

ggplot() + geom_sf(data = DEU) +
    geom_sf(aes(col = station_name), data = meta, cex = 4) +
    ggtitle("Just for Reto, can be removed later")
```

The data set to train the statistical post-processing models consists of
observed near surface temperature ($t_{2m}$) as well as bilinearely
interpolated forecasts of the near-surface temperature ($ens$) from the ECMWF
ensemble with $50+1$ members ($0000$ UTC run) covering the two years
2017 and 2018.

For simplicity, the data set is further restricted to two forecast steps:
$+108h$ and $+120h$ which correspond to a forecast horizon of $+4$ days and
$12$ hours ($1200$ UTC) and $+5$ days ($0000$ UTC) to highlight possible
differences in the statistical characteristic for different times of the day
(noon/midnight).

For each station, forecast step, and date, the ensemble mean
($\overline{\mathrm{ens}}$) as well as the ensemble log-standard deviation
($\log(\mathrm{sd}(ens))$) is calculated which serve as the independent
variables (covariates) in the statistical model. In addition, the day of 
the year ($\mathrm{yday}$; Julian day $-1$) is added as an additional
to model varying seasonal effects.

Infromation regarding the
`r xfun::embed_file("etl.py", name = "etl.py", text = "Python script")`
for downloading and preparing the data set as described are given in the Open Research/Code Availability section.






### Methodology

As described by @lang2020 in detail, the response (observed temperature;
$t_{2m}$) is assumed to follow a Gaussian distribution
$\mathcal{N}()$ defined by the two parameters $\mu$ (location) and
$\sigma$ (scale).

$$
t_{2m} \sim \mathcal{N}(\mu, \sigma)
$$

Both parameters can be expressed by an additive predictor $\eta_\bullet$
including zero or more explanatory variables. In the classical non-homogeneous
Gaussian regression, the following specification is frequently used:

$$
\mu = \eta_\mu = \beta_0 + \beta_1 \overline{\text{ens}},
$$

$$
\log(\sigma) = \eta_\sigma = \gamma_0 + \gamma_1 \log(\text{sd}(\text{ens})),
$$

where the ensemble mean ($\overline{\text{ens}}$) drives the location, while
the ensemble standard deviation ($\text{sd}(\text{ens})$) drives the scale of
the distribution. The log-link for the scale parameter is used to ensure positivity.
Both predictors $\eta_\bullet$ allow to correct for a
potential forecast bias ($\beta_0$; $\gamma_0$) as well as adjusting the linear
relationship between the response and the 
corresponding covariate (via $\beta_1$; $\gamma_1$).

However, ensemble forecast errors might show a seasonal dependency, e.g., a
positive bias during the cold season and a warm bias during the warm season.
In the early days of ensemble model output statistics @gneiting2005 proposed
to address this seasonality by using a rolling window training period (e.g., $\pm30$days).
Here, we apply allow the statistical model to depict such seasonal dependencies
by extending the two additive predictors,

$$
\mu = \beta_0(\text{yday}) + \beta_1(\text{yday}) \cdot \overline{\text{ens}},
$$ {#eq-mu}

$$
\log(\sigma) = \gamma_0(\text{yday}) + \gamma_1(\text{yday}) \cdot \log(\text{sd}(\text{ens})),
$$ {#eq-sigma}

that all regression coefficients are now smooth functions which depend on the day of the year
($f(\text{yday}$); cyclic P-splines).
For a bias free ensemble whose spread matches with the forecast uncertainty
the interpretation of the coefficients is as follows $\beta_0$/$\gamma_0$ would be $0.0$,
while $\beta_1$/$\gamma_1$ would be $1.0$ resulting in $\mu = \overline{\text{ens}}$ and
$\log(\sigma) = \log(\text{sd}(\text{ens}))$.



```{r setup}
#| code-fold: true
library("tidyverse")
library("bamlss")
set.seed(6020) # seed for reproducibility

train_models <- function(df, verbose = FALSE) {
    df$log_ens_sd <- log(df$ens_sd)

    f <- list(
        t2m_obs ~ s(yday, bs = "cc") + s(yday, bs = "cc", by = ens_mean),
        ~ s(yday, bs = "cc") + s(yday, bs = "cc", by = log_ens_sd)
    )
    # Caching estimated models for development purposes
    require("digest")
    cached_mod <- sprintf("_cached_bamlss_%s_%s.rds", digest(df), digest(f))
    if (file.exists(cached_mod)) {
        return(readRDS(cached_mod))
    }

    b <- bamlss(f, data = df, verbose = verbose, n.iter = 12000, burnin = 2000, thin = 10)

    saveRDS(b, cached_mod)
    return(b)
}

c95 <- function (x) {
    qx <- quantile(x, probs = c(0.025, 0.50, 0.975), na.rm = TRUE)
    qx <- c(qx[[1]], mean(x), qx[[3]])
    names(qx) <- c("lower", "mid", "upper")
    return(qx)
}

predict_effects <- function(b, file_name) {
    # Extracting station ID and forecast step (in hours) form csv file name
    station <- regmatches(file_name, regexpr("(?<=[_])[0-9]+(?=_)", file_name, perl = TRUE)) # char!
    step    <- as.integer(regmatches(file_name, regexpr("(?<=_)[0-9]+(?=\\.csv$)", file_name, perl = TRUE)))

    # Setting up 'grid' (df) with effects to be computed
    args <- data.frame(term  = c("s(yday)", "s(yday,by=ens_mean)", "s(yday)", "s(yday,by=log_ens_sd)"),
                       param = rep(c("mu", "sigma"), each = 2),
                       coef  = paste("varying", rep(c("intercept", "coef"), times = 2), sep = "_"))

    # Compute effects
    res <- list()
    nd  <- data.frame(yday = 0:366, ens_mean = 1, log_ens_sd = 1)
    for (i in seq_len(NROW(args))) {
        res[[i]] <- predict(b, nd, term = args$term[i], intercept = FALSE, type = "link", FUN = c95, model = args$param[i]) %>%
                    as_tibble() %>%
                    mutate(yday = nd$yday) %>%
                    pivot_longer(-yday, names_to = "prob") %>%
                    mutate(param = args$param[i], coef = args$coef[i], step = step, station = station)
    }
    return(bind_rows(res))
}

# Finding and reading available datasets
files <- list.files(pattern = "euppens.*csv")
data  <- setNames(map(files, read_csv), files)

# Training post-processing models
models <- setNames(map(data, train_models), files)

# Calculating estimated effects
effects <- map2_dfr(models, files, predict_effects)
stations <- list(id = c("5371", "5839", "3730"), name = c("Wasserkuppe", "Emden", "Oberstdorf"))
effects <- transform(effects, station = factor(station, stations$id, stations$name))
```






### Estimates and Results

```{r}
#| include: false
# Average mean effect gamma_0 and gamma_1 for Emden +108
tmp <- subset(effects, param == "sigma" & step == 108 & station == "Emden" & prob == "mid")
emden <- list("gamma_0" = mean(subset(tmp, coef == "varying_intercept")$value),
              "gamma_1" = mean(subset(tmp, coef == "varying_intercept")$value))
```

@fig-effects show the esimates of the effects from @eq-mu and @eq-sigma. While the
columns contain the effects for the two forecast steps, the different
effects are shown in the rows. Exemplarily, two sets of contrasting effects will be
described briefly.

For station Emden, $+108h$ ahead (green; left column) both effects for the location
parameter $mu$ ($\beta_0$, $\beta_1$) are close to $0.0$ and $1.0$, respectively.
This means that a change of $1^{\circ}C$ in the ensemble mean corresponds to a
change of $1^{\circ}C$ in the expected two meter temperature.
The effects for the log-scale ($\log(\sigma)$; $\gamma_0$, $\gamma_1$)
also show no distinct seasonal pattern with an average mean effect of
$\bar{\gamma}_0 = `r round(emden$gamma_0, 3)`$ and
$\bar{\gamma}_1 = `r round(emden$gamma_0, 3)`$ which indicates that the ensemble is overall
able to provide valuable uncertainty information but is slightly overdispersive which is not
surprising as the ensemble provides an average uncertainty over a larger grid box.

In contrast, the effects for station Wasserkuppe $+120h$ (red; right column)
shows a completely different picture. $\beta_0$ shows a strong seasonal pattern
with positive values during the cold season where the ensemble on average
underpredict temperatures (forecasts too cold) and negative values during summer where
the ensemble tends to overpredict temperatures (forecasts too warm). A similar but inverted
picture is shown for $\beta_1$ which shows a minimum in winter and a maximum over summer.
A similar pattern can be found for $\gamma_0$ and $\gamma_1$, where a high $\gamma_0$ in
combination with a small $\gamma_1$ means that the statistical model relies less on the
actual ensemble uncertainty (cold season), whereas duruing summer the ensemble provides
more reliable uncertainty information.


```{r plot_vertical_all}
#| label: fig-effects
#| fig-cap: Estimated seasonal varying effects $\beta_0(\text{yday})$, $\beta_1(\text{yday})$,
#|          $\gamma_0(\text{yday})$, and $\gamma_1(\text{yday})$ (top down) for the two
#|          forecast steps $+108h$ (noon) and $+120h$ (midnight).
#|          The lines show the mean effect (solid) as well as the 95% confidence interval (dashed) of
#|          all three stations.
#| fig.width: 5
#| fig.height: 7
#| code-fold: true
d2_plt <- effects %>% mutate(lty = ifelse(prob == "mid", "1", "4"), step = paste("+", step, "h", sep = ""))

beta_0  <- ggplot(subset(d2_plt, param == "mu" & coef == "varying_intercept")) +
           geom_line(aes(x = yday, y = value, linetype = lty, group = interaction(station, prob), col = station)) +
           labs(y = expression(beta[0]), x = NULL) +
           facet_grid(rows = NULL, cols = vars(step), switch = "y") +
           guides(linetype = "none") +
           theme_minimal()
beta_1  <- ggplot(subset(d2_plt, param == "mu" & coef == "varying_coef")) +
           geom_line(aes(x = yday, y = value, linetype = lty, group = interaction(station, prob), col = station)) +
           labs(y = expression(beta[1]), x = NULL) +
           facet_grid(rows = NULL, cols = vars(step), switch = "y") +
           guides(linetype = "none") +
           theme_minimal()
gamma_0 <- ggplot(subset(d2_plt, param == "sigma" & coef == "varying_intercept")) +
           geom_line(aes(x = yday, y = value, linetype = lty, group = interaction(station, prob), col = station)) +
           labs(y = expression(gamma[0]), x = NULL) +
           facet_grid(rows = NULL, cols = vars(step), switch = "y") +
           guides(linetype = "none") +
           theme_minimal()
gamma_1 <- ggplot(subset(d2_plt, param == "sigma" & coef == "varying_coef")) +
           geom_line(aes(x = yday, y = value, linetype = lty, group = interaction(station, prob), col = station)) +
           labs(y = expression(gamma[1])) +
           facet_grid(rows = NULL, cols = vars(step), switch = "y") +
           guides(linetype = "none") +
           theme_minimal()

library("lemon")
grid_arrange_shared_legend(beta_0, beta_1, gamma_0, gamma_1, nrow = 4, ncol = 1, position = "bottom")
```



### Discussion

This 'proof of concept' demonstrates how the new benchmark dataset can be used
for a specific application ($2m$ temperature, station based, ensemble forecasts only)
using one of many methods suggested in research papers and applied studies over the
past decades. Keep in mind that this is intended to be a motivational example and not
any kind of reference method.





